{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who's Fake is it Anyway? HCVIS Proseminar Final Project\n",
    "---\n",
    "Davienne Gabriel<br>\n",
    "November 23rd, 2020\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "\n",
    "> This Jupyter Notebook will serve as the process component of the final paper. At each step I will explain the code and what it does. I will also provide some commentary on the choices I made along the way, and how those ultimately shaped the outcome of this exploratory project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the Modules and Corpra\n",
    "\n",
    "---\n",
    "\n",
    "> The first code block is used to initialize the modules within the notebook, or to 'get everything ready' so that they can be called up later in the document. The libraries that I am importing include the Natural Language Tool Kit, along with some data science libraries (numpy and pandas). Bokeh is used to visualize  the data at the end of the process.\n",
    "\n",
    "> There are a wide variety of python libraries that overlap in functionality. I could have chosen other modules to work within, which could have very well led to a different outcome in this project. That is not to say that there's a grand disparity in objective work done between these libraries, but that there are a myriad of paths to get to an end result (whatever that may be). I chose to work with NLTK, numpy and pandas, and Bokeh since I am familiar with these libraries. Something to consider in the future is incorporating other libraries or tools to explore the data, as it may yield results leading to further insight in the study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, FixedTicker, PrintfTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.resources import CDN\n",
    "\n",
    "from bokeh.palettes import Spectral9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This second code block is to render the corpra within the document. In order for these texts to be \"read\" by the NLTK, they need to be parsed into tokens. This process is done for each corpus relating to an artist, resulting in six distinct collections of words.\n",
    "\n",
    "> Initially, I wanted to use academic texts for this project. After trying to download and parse some PDFs relating to Han van Meegeren, I found that the OCR capabilities that I had handy weren't competent enough to actually read the PDFs. I made the decision to use text that I could access online -- specifically, grabbing text from the first couple of pages of a google search of the person. This method is problematic from a few standpoints, but I wanted to see (disregarding the algorithmic biases that would be present in the text) if there was a pattern that could be discerned at all from assembled text. As such, the following texts were gathered from initial results of a google search, which usually included biographic information, news articles, and a few exhibition summaries.\n",
    "\n",
    "> It was apparent when adding text for Han Van Meegeren and Elmyr De Hory that the sources specifically focused on their forgeries, where the text for the other four artists were more broad in what they covered. As a result, there is an overrepresentation of certain words for Meegeren and De Hory compared to the other four artists. Future exploration in this area with varying sources for text (especially from an academic vs. news standpoint) would be rich. Do certain words show up more in layman publications versus academic ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text file\n",
    "\n",
    "meegeren_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\meegren\\meegren.txt\", encoding=\"utf8\")\n",
    "\n",
    "# Tokenize it\n",
    "\n",
    "Meegeren = nltk.word_tokenize(meegeren_raw.read())\n",
    "\n",
    "dehory_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\dehory.txt\", encoding=\"utf8\")\n",
    "DeHory = nltk.word_tokenize(dehory_raw.read())\n",
    "\n",
    "koons_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\koons.txt\", encoding=\"utf8\")\n",
    "Koons = nltk.word_tokenize(koons_raw.read())\n",
    "\n",
    "prince_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\prince.txt\", encoding=\"utf8\")\n",
    "Prince = nltk.word_tokenize(prince_raw.read())\n",
    "\n",
    "lawler_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\lawler.txt\", encoding=\"utf8\")\n",
    "Lawler = nltk.word_tokenize(lawler_raw.read())\n",
    "\n",
    "sturtevant_raw = open(\"C:\\\\Users\\j'aam\\Desktop\\school\\HCVIS final\\sturtevant.txt\", encoding=\"utf8\")\n",
    "Sturtevant = nltk.word_tokenize(sturtevant_raw.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forgers',\n",
       " ',',\n",
       " 'by',\n",
       " 'nature',\n",
       " ',',\n",
       " 'prefer',\n",
       " 'anonymity',\n",
       " 'and',\n",
       " 'therefore',\n",
       " 'are',\n",
       " 'rarely',\n",
       " 'remembered',\n",
       " '.',\n",
       " 'An',\n",
       " 'exception',\n",
       " 'is',\n",
       " 'Han',\n",
       " 'van',\n",
       " 'Meegeren',\n",
       " '(',\n",
       " '1889â€“1947',\n",
       " ')',\n",
       " '.',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " \"'s\",\n",
       " 'story',\n",
       " 'is',\n",
       " 'absolutely',\n",
       " 'unique',\n",
       " 'and',\n",
       " 'may',\n",
       " 'be',\n",
       " 'justly',\n",
       " 'considered',\n",
       " 'the',\n",
       " 'most',\n",
       " 'dramatic',\n",
       " 'art',\n",
       " 'scam',\n",
       " 'of',\n",
       " 'the',\n",
       " 'twentieth',\n",
       " 'century',\n",
       " '.',\n",
       " 'In',\n",
       " '1937',\n",
       " ',',\n",
       " 'Abraham',\n",
       " 'Bredius',\n",
       " ',',\n",
       " 'who',\n",
       " 'as',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'authoritative',\n",
       " 'art',\n",
       " 'historians',\n",
       " 'had',\n",
       " 'dedicated',\n",
       " 'a',\n",
       " 'great',\n",
       " 'part',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life',\n",
       " 'to',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'Vermeer',\n",
       " ',',\n",
       " 'was',\n",
       " 'approached',\n",
       " 'by',\n",
       " 'a',\n",
       " 'lawyer',\n",
       " 'who',\n",
       " 'claimed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'trustee',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Dutch',\n",
       " 'family',\n",
       " 'estate',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'have',\n",
       " 'him',\n",
       " 'look',\n",
       " 'at',\n",
       " 'a',\n",
       " 'rather',\n",
       " 'large',\n",
       " 'painting',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Christ',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Disciples',\n",
       " 'at',\n",
       " 'Emmaus',\n",
       " '(',\n",
       " 'fig',\n",
       " '.',\n",
       " '1',\n",
       " ')',\n",
       " '.',\n",
       " 'Shortly',\n",
       " 'after',\n",
       " 'having',\n",
       " 'viewed',\n",
       " 'the',\n",
       " 'painting',\n",
       " ',',\n",
       " 'the',\n",
       " '83',\n",
       " 'year',\n",
       " 'old',\n",
       " 'art',\n",
       " 'historian',\n",
       " 'wrote',\n",
       " 'an',\n",
       " 'article',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Burlington',\n",
       " 'Magazine',\n",
       " ',',\n",
       " 'the',\n",
       " '``',\n",
       " 'art',\n",
       " 'bible',\n",
       " \"''\",\n",
       " 'of',\n",
       " 'the',\n",
       " 'times',\n",
       " ',',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'stated',\n",
       " ',',\n",
       " '``',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'moment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'life',\n",
       " 'of',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'of',\n",
       " 'art',\n",
       " 'when',\n",
       " 'he',\n",
       " 'finds',\n",
       " 'himself',\n",
       " 'suddenly',\n",
       " 'confronted',\n",
       " 'with',\n",
       " 'a',\n",
       " 'hitherto',\n",
       " 'unknown',\n",
       " 'painting',\n",
       " 'by',\n",
       " 'a',\n",
       " 'great',\n",
       " 'master',\n",
       " ',',\n",
       " 'untouched',\n",
       " ',',\n",
       " 'on',\n",
       " 'the',\n",
       " 'original',\n",
       " 'canvas',\n",
       " ',',\n",
       " 'and',\n",
       " 'without',\n",
       " 'any',\n",
       " 'restoration',\n",
       " ',',\n",
       " 'just',\n",
       " 'as',\n",
       " 'it',\n",
       " 'left',\n",
       " 'the',\n",
       " 'painter',\n",
       " \"'s\",\n",
       " 'studio',\n",
       " '.',\n",
       " 'And',\n",
       " 'what',\n",
       " 'a',\n",
       " 'picture',\n",
       " '!',\n",
       " 'Neither',\n",
       " 'the',\n",
       " 'beautiful',\n",
       " 'signature',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'nor',\n",
       " 'the',\n",
       " 'pointillÃ©s',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bread',\n",
       " 'which',\n",
       " 'Christ',\n",
       " 'is',\n",
       " 'blessing',\n",
       " ',',\n",
       " 'is',\n",
       " 'necessary',\n",
       " 'to',\n",
       " 'convince',\n",
       " 'us',\n",
       " 'that',\n",
       " 'we',\n",
       " 'have',\n",
       " 'hereâ€”I',\n",
       " 'am',\n",
       " 'inclined',\n",
       " 'to',\n",
       " 'sayâ€”the',\n",
       " 'masterpiece',\n",
       " 'of',\n",
       " 'Johannes',\n",
       " 'Vermeer',\n",
       " 'of',\n",
       " 'Delft',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'quite',\n",
       " 'different',\n",
       " 'from',\n",
       " 'all',\n",
       " 'his',\n",
       " 'other',\n",
       " 'paintings',\n",
       " 'and',\n",
       " 'yet',\n",
       " 'every',\n",
       " 'inch',\n",
       " 'a',\n",
       " 'Vermeer',\n",
       " '.',\n",
       " 'In',\n",
       " 'no',\n",
       " 'other',\n",
       " 'picture',\n",
       " 'by',\n",
       " 'the',\n",
       " 'great',\n",
       " 'master',\n",
       " 'of',\n",
       " 'Delft',\n",
       " 'do',\n",
       " 'we',\n",
       " 'find',\n",
       " 'such',\n",
       " 'sentiment',\n",
       " ',',\n",
       " 'such',\n",
       " 'a',\n",
       " 'profound',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Bible',\n",
       " 'storyâ€”a',\n",
       " 'sentiment',\n",
       " 'so',\n",
       " 'nobly',\n",
       " 'human',\n",
       " 'expressed',\n",
       " 'through',\n",
       " 'the',\n",
       " 'medium',\n",
       " 'of',\n",
       " 'highest',\n",
       " 'art',\n",
       " '.',\n",
       " \"''\",\n",
       " 'Few',\n",
       " 'doubts',\n",
       " 'were',\n",
       " 'advanced',\n",
       " 'by',\n",
       " 'his',\n",
       " 'colleagues',\n",
       " 'since',\n",
       " 'Bredius',\n",
       " \"'\",\n",
       " 'opinion',\n",
       " 'was',\n",
       " 'taken',\n",
       " 'as',\n",
       " 'gospel',\n",
       " 'in',\n",
       " 'the',\n",
       " 'art',\n",
       " 'world',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'been',\n",
       " 'nick-named',\n",
       " '``',\n",
       " 'the',\n",
       " 'Pope',\n",
       " '.',\n",
       " \"''\",\n",
       " 'This',\n",
       " 'work',\n",
       " 'that',\n",
       " 'today',\n",
       " 'seems',\n",
       " 'so',\n",
       " 'heavy',\n",
       " 'handed',\n",
       " 'and',\n",
       " 'awkward',\n",
       " 'was',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'a',\n",
       " 'fake',\n",
       " 'by',\n",
       " 'Han',\n",
       " 'van',\n",
       " 'Meegeren',\n",
       " ',',\n",
       " 'a',\n",
       " 'mediocre',\n",
       " 'Dutch',\n",
       " 'artist',\n",
       " 'who',\n",
       " 'had',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'worked',\n",
       " 'in',\n",
       " 'relative',\n",
       " 'obscurity',\n",
       " '.',\n",
       " 'In',\n",
       " 'May',\n",
       " '1945',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'was',\n",
       " 'arrested',\n",
       " ',',\n",
       " 'charged',\n",
       " 'with',\n",
       " 'collaborating',\n",
       " 'with',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'and',\n",
       " 'imprisoned',\n",
       " '.',\n",
       " 'His',\n",
       " 'name',\n",
       " 'had',\n",
       " 'been',\n",
       " 'traced',\n",
       " 'to',\n",
       " 'the',\n",
       " 'sale',\n",
       " 'made',\n",
       " 'during',\n",
       " 'WW',\n",
       " 'II',\n",
       " 'of',\n",
       " 'what',\n",
       " 'was',\n",
       " 'then',\n",
       " 'believed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'an',\n",
       " 'authentic',\n",
       " 'painting',\n",
       " 'Vermeer',\n",
       " 'to',\n",
       " 'Nazi',\n",
       " 'Field-Marshal',\n",
       " 'Hermann',\n",
       " 'Goering',\n",
       " '.',\n",
       " 'Shortly',\n",
       " 'after',\n",
       " ',',\n",
       " 'to',\n",
       " 'general',\n",
       " 'disbelief',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'came',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " 'very',\n",
       " 'original',\n",
       " 'defense',\n",
       " 'against',\n",
       " 'the',\n",
       " 'accusation',\n",
       " 'of',\n",
       " 'collaboration',\n",
       " ',',\n",
       " 'then',\n",
       " 'punishable',\n",
       " 'by',\n",
       " 'death',\n",
       " '.',\n",
       " 'He',\n",
       " 'claimed',\n",
       " 'that',\n",
       " 'the',\n",
       " 'painting',\n",
       " ',',\n",
       " 'The',\n",
       " 'Woman',\n",
       " 'Taken',\n",
       " 'in',\n",
       " 'Adultery',\n",
       " ',',\n",
       " 'was',\n",
       " 'not',\n",
       " 'a',\n",
       " 'Vermeer',\n",
       " 'but',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'forgery',\n",
       " 'by',\n",
       " 'his',\n",
       " 'own',\n",
       " 'hand',\n",
       " '.',\n",
       " 'Moreover',\n",
       " ',',\n",
       " 'since',\n",
       " 'he',\n",
       " 'had',\n",
       " 'traded',\n",
       " 'the',\n",
       " 'false',\n",
       " 'Vermeer',\n",
       " 'for',\n",
       " '200',\n",
       " 'original',\n",
       " 'Dutch',\n",
       " 'paintings',\n",
       " 'seized',\n",
       " 'by',\n",
       " 'Goering',\n",
       " 'in',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'he',\n",
       " 'war',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'believed',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'a',\n",
       " 'national',\n",
       " 'hero',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'a',\n",
       " 'Nazi',\n",
       " 'collaborator',\n",
       " '.',\n",
       " 'He',\n",
       " 'also',\n",
       " 'claimed',\n",
       " 'to',\n",
       " 'have',\n",
       " 'painted',\n",
       " 'five',\n",
       " 'other',\n",
       " '``',\n",
       " 'Vermeers',\n",
       " \"''\",\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'two',\n",
       " '``',\n",
       " 'Pieter',\n",
       " 'de',\n",
       " 'Hoochs',\n",
       " \"''\",\n",
       " 'all',\n",
       " 'of',\n",
       " 'which',\n",
       " 'had',\n",
       " 'surfaced',\n",
       " 'on',\n",
       " 'the',\n",
       " 'art',\n",
       " 'market',\n",
       " 'since',\n",
       " '1937',\n",
       " '.',\n",
       " 'The',\n",
       " 'trial',\n",
       " 'of',\n",
       " 'Han',\n",
       " 'van',\n",
       " 'Meegeren',\n",
       " '(',\n",
       " 'fig',\n",
       " '.',\n",
       " '2',\n",
       " ')',\n",
       " 'began',\n",
       " 'on',\n",
       " '29',\n",
       " 'October',\n",
       " ',',\n",
       " '1947',\n",
       " 'in',\n",
       " 'Room',\n",
       " '4',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Regional',\n",
       " 'Court',\n",
       " 'in',\n",
       " 'Amsterdam',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'to',\n",
       " 'demonstrate',\n",
       " 'his',\n",
       " 'case',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'arranged',\n",
       " 'that',\n",
       " ',',\n",
       " 'under',\n",
       " 'police',\n",
       " 'guard',\n",
       " 'before',\n",
       " 'the',\n",
       " 'court',\n",
       " ',',\n",
       " 'he',\n",
       " 'would',\n",
       " 'paint',\n",
       " 'another',\n",
       " '``',\n",
       " 'Vermeer',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Jesus',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'Doctors',\n",
       " '(',\n",
       " 'fig',\n",
       " '.',\n",
       " '3',\n",
       " ')',\n",
       " ',',\n",
       " 'using',\n",
       " 'the',\n",
       " 'materials',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'he',\n",
       " 'had',\n",
       " 'employed',\n",
       " 'for',\n",
       " 'the',\n",
       " 'other',\n",
       " 'forgeries',\n",
       " '.',\n",
       " 'During',\n",
       " 'the',\n",
       " 'incredible',\n",
       " 'two',\n",
       " 'year',\n",
       " 'trial',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'confessed',\n",
       " 'that',\n",
       " '``',\n",
       " 'spurred',\n",
       " 'by',\n",
       " 'the',\n",
       " 'disappointment',\n",
       " 'of',\n",
       " 'receiving',\n",
       " 'no',\n",
       " 'acknowledgements',\n",
       " 'from',\n",
       " 'artists',\n",
       " 'and',\n",
       " 'critics',\n",
       " '...',\n",
       " '.I',\n",
       " 'determined',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'my',\n",
       " 'worth',\n",
       " 'as',\n",
       " 'a',\n",
       " 'painter',\n",
       " 'by',\n",
       " 'making',\n",
       " 'a',\n",
       " 'perfect',\n",
       " 'seventeenth-century',\n",
       " 'canvas',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'During',\n",
       " 'the',\n",
       " 'investigation',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'revealed',\n",
       " 'that',\n",
       " 'having',\n",
       " 'once',\n",
       " 'fooled',\n",
       " 'the',\n",
       " 'art',\n",
       " 'world',\n",
       " 'with',\n",
       " 'Christ',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Disciples',\n",
       " 'at',\n",
       " 'Emmaus',\n",
       " ',',\n",
       " 'probably',\n",
       " 'his',\n",
       " 'best',\n",
       " 'forgery',\n",
       " ',',\n",
       " 'he',\n",
       " 'was',\n",
       " 'encouraged',\n",
       " 'to',\n",
       " 'try',\n",
       " 'new',\n",
       " 'forgeries',\n",
       " '.',\n",
       " 'He',\n",
       " 'painted',\n",
       " 'a',\n",
       " 'head',\n",
       " 'of',\n",
       " 'Christ',\n",
       " ',',\n",
       " 'sold',\n",
       " 'it',\n",
       " 'through',\n",
       " 'an',\n",
       " 'intermediary',\n",
       " 'and',\n",
       " 'then',\n",
       " '``',\n",
       " 'found',\n",
       " \"''\",\n",
       " 'the',\n",
       " 'Last',\n",
       " 'Supper',\n",
       " 'for',\n",
       " 'which',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'supposed',\n",
       " 'study',\n",
       " '.',\n",
       " 'The',\n",
       " 'buyer',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Christ',\n",
       " 'painting',\n",
       " 'was',\n",
       " 'only',\n",
       " 'too',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'snap-up',\n",
       " 'the',\n",
       " 'full',\n",
       " 'scale',\n",
       " 'painting',\n",
       " '.',\n",
       " '``',\n",
       " '1',\n",
       " \"''\",\n",
       " 'Perhaps',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'problem',\n",
       " 'that',\n",
       " 'faced',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'was',\n",
       " 'the',\n",
       " 'secrecy',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'had',\n",
       " 'to',\n",
       " 'work',\n",
       " '.',\n",
       " 'He',\n",
       " 'could',\n",
       " 'hire',\n",
       " 'no',\n",
       " 'models',\n",
       " ',',\n",
       " 'since',\n",
       " 'they',\n",
       " 'might',\n",
       " 'talk',\n",
       " '.',\n",
       " 'For',\n",
       " 'The',\n",
       " 'Last',\n",
       " 'Supper',\n",
       " 'he',\n",
       " 'was',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'rely',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'his',\n",
       " 'imagination',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'wonder',\n",
       " 'that',\n",
       " 'he',\n",
       " 'dared',\n",
       " 'such',\n",
       " 'a',\n",
       " 'accomplished',\n",
       " 'composition',\n",
       " ',',\n",
       " 'involving',\n",
       " '13',\n",
       " 'figures',\n",
       " 'in',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'poses',\n",
       " '.',\n",
       " 'At',\n",
       " 'one',\n",
       " 'point',\n",
       " 'he',\n",
       " 'stole',\n",
       " 'directly',\n",
       " 'from',\n",
       " 'Vermeer',\n",
       " ',',\n",
       " 'using',\n",
       " 'the',\n",
       " 'head',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Girl',\n",
       " 'with',\n",
       " 'a',\n",
       " 'Pearl',\n",
       " 'Earring',\n",
       " 'for',\n",
       " 'his',\n",
       " 'head',\n",
       " 'of',\n",
       " 'Saint',\n",
       " 'John',\n",
       " '(',\n",
       " 'fig',\n",
       " '.',\n",
       " '4',\n",
       " ')',\n",
       " '.',\n",
       " '``',\n",
       " '2',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'spent',\n",
       " 'four',\n",
       " 'years',\n",
       " 'working',\n",
       " 'out',\n",
       " 'techniques',\n",
       " 'for',\n",
       " 'making',\n",
       " 'a',\n",
       " 'new',\n",
       " 'painting',\n",
       " 'look',\n",
       " 'old',\n",
       " '.',\n",
       " 'The',\n",
       " 'biggest',\n",
       " 'problem',\n",
       " 'was',\n",
       " 'getting',\n",
       " 'oil',\n",
       " 'paint',\n",
       " 'to',\n",
       " 'harden',\n",
       " 'thoroughly',\n",
       " ',',\n",
       " 'a',\n",
       " 'process',\n",
       " 'that',\n",
       " 'normally',\n",
       " 'takes',\n",
       " '50',\n",
       " 'years',\n",
       " '.',\n",
       " 'He',\n",
       " 'solved',\n",
       " 'the',\n",
       " 'dilemma',\n",
       " 'by',\n",
       " 'mixing',\n",
       " 'his',\n",
       " 'pigments',\n",
       " 'with',\n",
       " 'a',\n",
       " 'synthetic',\n",
       " 'resin',\n",
       " ',',\n",
       " 'Bakelite',\n",
       " ',',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'oil',\n",
       " ',',\n",
       " 'and',\n",
       " 'subsequently',\n",
       " 'baking',\n",
       " 'the',\n",
       " 'canvas',\n",
       " '.',\n",
       " 'Now',\n",
       " 'he',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'begin',\n",
       " '.',\n",
       " 'He',\n",
       " 'took',\n",
       " 'an',\n",
       " 'actual',\n",
       " 'seventeenth-century',\n",
       " 'painting',\n",
       " 'and',\n",
       " 'removed',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " 'picture',\n",
       " 'with',\n",
       " 'pumice',\n",
       " 'and',\n",
       " 'water',\n",
       " ',',\n",
       " 'being',\n",
       " 'most',\n",
       " 'careful',\n",
       " 'not',\n",
       " 'to',\n",
       " 'obliterate',\n",
       " 'the',\n",
       " 'network',\n",
       " 'of',\n",
       " 'cracks',\n",
       " ',',\n",
       " 'which',\n",
       " 'had',\n",
       " 'an',\n",
       " 'important',\n",
       " 'role',\n",
       " 'to',\n",
       " 'play',\n",
       " '.',\n",
       " '``',\n",
       " '3',\n",
       " 'After',\n",
       " 'having',\n",
       " 'tried',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'at',\n",
       " 'a',\n",
       " 'few',\n",
       " 'typical',\n",
       " 'Vermeer',\n",
       " 'interior',\n",
       " 'composition',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'renowned',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'had',\n",
       " 'what',\n",
       " 'might',\n",
       " 'be',\n",
       " 'called',\n",
       " 'his',\n",
       " 'own',\n",
       " 'stroke',\n",
       " 'of',\n",
       " 'genius',\n",
       " '.',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'forging',\n",
       " 'variations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'interiors',\n",
       " 'which',\n",
       " 'could',\n",
       " 'be',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'works',\n",
       " 'hanging',\n",
       " 'in',\n",
       " 'museums',\n",
       " ',',\n",
       " 'Van',\n",
       " 'Meegeren',\n",
       " 'chose',\n",
       " 'to',\n",
       " 'forge',\n",
       " 'an',\n",
       " 'early',\n",
       " 'Vermeer',\n",
       " 'of',\n",
       " 'a',\n",
       " 'religious',\n",
       " 'theme',\n",
       " 'based',\n",
       " 'on',\n",
       " 'a',\n",
       " 'composition',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what the collected text looks like when it is tokenized\n",
    "\n",
    "Meegeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Terms, Create a Function\n",
    "\n",
    "---\n",
    "\n",
    "> This code block defines the array of terms that I wanted to see the frequency of in each text. As I have outlined with the thesis of this project, all of these words are similar but they certainly do not mean the same thing. In fact, they have very specific meanings as it relates to conceptions of crime and artistry. I wanted to see how these words, in their occurrence used in these texts relating to the artists, reflected perceptions of the artist and the objective term for their particular artwork. Are the authors of these texts (whoever they are) using synonyms to fluff up their work, or are there deliberate choices being made in how the work is described? \n",
    "\n",
    "> These words were chosen at random, and were not selected based on any preconceived notions or analytics pointing to their common use in the texts. To my surprise, there was only one word that did not occur at all (\"knockoff\"), and that all the other words chosen appeared at least once within the corpra. Further study in this project could be done in the word choice, along with more robust processing to identify sentiment being used in relation to these words and the artists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_terms = \"forger\", \"forgery\", \"duplicate\", \"copy\", \"fraud\", \"fake\", \"appropriation\", \"appropriate\", \"replica\", \"replication\", \"reproduction\", \"facsimile\", \"imitation\", \"counterfeit\", \"knockoff\", \"dupe\", \"mimic\", \"plagiarism\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This code block defines a function that I used to find the frequency of these words within each text. For each text that is passed through, the function uses the terms I defined in copy_terms and finds their frequency. It outputs a table with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_freq_table(tokenlist):\n",
    "    \n",
    "    # Create a frequency distribution for the tokenized text\n",
    "    \n",
    "    freqDist = FreqDist(tokenlist)\n",
    "    \n",
    "    # Create an empty array to append with each term and the term's totals\n",
    "    \n",
    "    totals = make_array()\n",
    "    \n",
    "    # Iterate finding the frequency for each term in the copy_terms array\n",
    "    \n",
    "    for i in copy_terms:\n",
    "        totals = np.append(totals, freqDist[i])\n",
    "        \n",
    "    # Create a table with the words and their corresponding frequency\n",
    "        \n",
    "    frequency = Table().with_columns(\n",
    "        \"Word\", copy_terms,\n",
    "        \"Frequency\", totals\n",
    "        )\n",
    "    \n",
    "    # Output table\n",
    "    \n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Word</th> <th>Frequency</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>forger       </td> <td>35       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>forgery      </td> <td>51       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>duplicate    </td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>copy         </td> <td>4        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>fraud        </td> <td>9        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>fake         </td> <td>21       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>appropriation</td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>appropriate  </td> <td>1        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>replica      </td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>replication  </td> <td>1        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>reproduction </td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>facsimile    </td> <td>3        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>imitation    </td> <td>6        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>counterfeit  </td> <td>3        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>knockoff     </td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dupe         </td> <td>1        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>mimic        </td> <td>0        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>plagiarism   </td> <td>0        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example of the function with the Meegeren tokenized text passed through it\n",
    "\n",
    "make_word_freq_table(Meegeren).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Convert Table into a Dataframe for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This code block converts the table into dataframe that can be more easily read and manipulated by the visualization tool. I could have used the dataframe library from the start of this project, but it was only when I began working with the visualization library that I realized I needed to have the frequencies in a dataframe. Converting the data mid-way through the project is not a best practice and could be something easily changed in future versions of this project to omit this extra step and allow for a seamless transition between steps.\n",
    "\n",
    "> Regardless, it still works for this project in it's current form.\n",
    "\n",
    "> Along with having to convert the table into a dataframe, I had to add rows with nothing but zeroes at the very beginning and end. I found this as a solution to \"properly\" showing the data in the visualization below, as otherwise the area glyphs created by Bokeh would not properly fill in.\n",
    "\n",
    "> Another issue I ran into was that the data visualization library would not read the column \"De Hory\" as spaced, or \"De_Hory\" with an underscore. I had to change all instances of this artist's name to \"DeHory\" in order to please the data visualization deities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe that has all of the frequencies collected for each artist using the function defined earlier.\n",
    "# The part of the function that is needed is the frequency, not the words, so only the second column is selected.\n",
    "\n",
    "data = {\n",
    "        'Meegeren': make_word_freq_table(Meegeren).column(1), \n",
    "        'DeHory': make_word_freq_table(DeHory).column(1),\n",
    "        'Koons': make_word_freq_table(Koons).column(1),\n",
    "        'Prince': make_word_freq_table(Prince).column(1),\n",
    "        'Lawler': make_word_freq_table(Lawler).column(1),\n",
    "        'Sturtevant': make_word_freq_table(Sturtevant).column(1)\n",
    "    }\n",
    "\n",
    "# Refining the dataframe so that it can be parsed by the data visualization tool.\n",
    "# Adding a row of zeroes to the beginning and end of the table so that the glyph will properly render in the next step.\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df = pd.concat([df, df.tail(1)], axis=0)\n",
    "df.iloc[-1] = 0.0\n",
    "df.iloc[0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meegeren</th>\n",
       "      <th>DeHory</th>\n",
       "      <th>Koons</th>\n",
       "      <th>Prince</th>\n",
       "      <th>Lawler</th>\n",
       "      <th>Sturtevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Meegeren  DeHory  Koons  Prince  Lawler  Sturtevant\n",
       "0        0.0     0.0    0.0     0.0     0.0         0.0\n",
       "1       51.0    19.0    0.0     0.0     0.0         0.0\n",
       "2        0.0     0.0    1.0     0.0     0.0         1.0\n",
       "3        4.0     1.0    3.0     4.0     0.0         2.0\n",
       "4        9.0     8.0    0.0     0.0     0.0         0.0\n",
       "5       21.0    14.0    0.0     1.0     0.0         0.0\n",
       "6        0.0     0.0    0.0    25.0     7.0         5.0\n",
       "7        1.0     0.0    0.0     2.0     0.0         1.0\n",
       "8        0.0     0.0    1.0     0.0     0.0         2.0\n",
       "9        1.0     0.0    0.0     0.0     0.0         0.0\n",
       "10       0.0     0.0    1.0     0.0     0.0         5.0\n",
       "11       3.0     0.0    0.0     0.0     0.0         0.0\n",
       "12       6.0     0.0    0.0     0.0     0.0         0.0\n",
       "13       3.0     1.0    0.0     0.0     0.0         0.0\n",
       "14       0.0     0.0    0.0     0.0     0.0         0.0\n",
       "15       1.0     0.0    0.0     0.0     0.0         0.0\n",
       "16       0.0     2.0    1.0     0.0     0.0         0.0\n",
       "17       0.0     0.0    0.0     2.0     0.0         1.0\n",
       "17       0.0     0.0    0.0     0.0     0.0         0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what the dataframe looks like in table form.\n",
    "# While the words are omitted here, they will be added in the visualization in the next step.\n",
    "# Each number corresponds with a word in the array (1 to forger, 2 to forgery, 3 to duplicate, etc.).\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Visualization Code\n",
    "\n",
    "---\n",
    "\n",
    "> This is the code block in which I use the Bokeh data visualization library in order to visualize the data I've created. As mentioned before, there are a wide variety of libraries that I could have used for this step. I use Bokeh due to being familiar with it and I like it's interactivity features.\n",
    "\n",
    "> The code to render the graph itself was mostly taken from the documentation on the Bokeh website for ridge graphs. The code had to be altered in order to suit my data, not only in the relevant inputs but in the structure as well.\n",
    "\n",
    "> At this step I ran into several issues getting the data to successfully \"visualize\", or rather, to be visualized in a way that can even be interpreted by a human viewer. As mentioned before, I had made changes such as converting my data into a dataframe, changing names to suit the program (De Hory to DeHory), and adding rows of zeroes to have the glyphs render correctly. Another issue was that when I defined the x_range with the original copy_terms, the graph would render in such a way that the data was offset from the x axis. A change to bypass this was to manually define the x axis and override the numbers with the original terms. Such a change was necessary, but also more laborious than the intended functions of the libraries to reduce redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter data into the visualization library's preferred data structure.\n",
    "# This visualization library can be used without this step, but it can be difficult to render certain visualizations\n",
    "# without using the library's data structure. \n",
    "\n",
    "source = ColumnDataSource(data=dict(x=df.index.values))\n",
    "\n",
    "# Function used to create ridge glyphs, as created by the visualization library\n",
    "\n",
    "def ridge(category, data, scale=0.075):\n",
    "    return list(zip([category] * len(data), scale * data))\n",
    "\n",
    "# Categories, each artist as a category\n",
    "\n",
    "cats = list(['Meegeren', 'DeHory', 'Koons', 'Prince', 'Lawler', 'Sturtevant'])\n",
    "\n",
    "# Defining the parameters of the graph itself\n",
    "\n",
    "p = figure(\n",
    "           y_range=cats, \n",
    "           plot_width=1000,\n",
    "           toolbar_location=None, \n",
    "           title=\"Frequency of Terms In Reference to Artists\"\n",
    "           )\n",
    "\n",
    "# Creating the ridge glyphs for each category and each frequency associated with it.\n",
    "\n",
    "for i, cat in enumerate(cats):\n",
    "    y = ridge(cat, df[cat])\n",
    "    source.add(y, cat)\n",
    "    p.patch('x', \n",
    "            cat, \n",
    "            color=Spectral9[i], \n",
    "            alpha=0.6, \n",
    "            line_color=\"black\", \n",
    "            source=source\n",
    "           )\n",
    "\n",
    "# Visual options, such as making the font larger, changing the orientation of the words on the x axis\n",
    "# changing the color of the lines within the graph, and adding padding to the y-axis \n",
    "\n",
    "p.title.text_font_size = \"15pt\"\n",
    "p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "p.yaxis.major_label_text_font_size = \"10pt\"\n",
    "\n",
    "p.xaxis.major_label_orientation = 1\n",
    "\n",
    "p.outline_line_color = None\n",
    "p.background_fill_color = \"#efefef\"\n",
    "\n",
    "p.ygrid.grid_line_color = \"#dddddd\"\n",
    "p.xgrid.grid_line_color = \"#dddddd\"\n",
    "\n",
    "# As mentioned earlier, manual override of the x_range and x axis label\n",
    "\n",
    "p.xaxis.ticker = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "p.xaxis.major_label_overrides = {0: \"forger\", \n",
    "                                 1: \"forgery\", \n",
    "                                 2: \"duplicate\",\n",
    "                                 3: \"copy\",\n",
    "                                 4: \"fraud\",\n",
    "                                 5: \"fake\",\n",
    "                                 6: \"appropriation\",\n",
    "                                 7: \"appropriate\",\n",
    "                                 8: \"replica\",\n",
    "                                 9: \"replication\",\n",
    "                                 10: \"reproduction\",\n",
    "                                 11: \"facsimile\",\n",
    "                                 12: \"imitation\",\n",
    "                                 13: \"counterfeit\",\n",
    "                                 14: \"knockoff\",\n",
    "                                 15: \"dupe\",\n",
    "                                 16: \"mimic\",\n",
    "                                 17: \"plagarism\"}\n",
    "\n",
    "p.y_range.range_padding = 0.12\n",
    "p.xaxis.axis_line_width = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = file_html(p, CDN, \"my plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
